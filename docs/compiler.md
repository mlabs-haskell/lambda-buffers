# _Compiler_ Spec & Design

The _Compiler_ component sits between the _Frontend_ component and the code
generation component named _Codegen_. The purpose of the _Compiler_ is to
typecheck terms generated by the Frontend (terms referred to as _Compiler Input_)
and perform other additional validation checks. The end goal of the _Compiler_
is to ensure that the _Codegen_ component is capable of processing the _Compiler
Output_.

## _Compiler_ interface

The _Compiler_ operates on the _Compiler Input proto_ - enabling, any _Frontend_
to interface with the _Compiler_ in a language agnostic manner.

Similarly, the _Compiler Output_ is also a _proto_ that is then consumed by
_Codegen_ modules, able to be written in any programming environment capable of
communicating via Google Protocol Buffers.

## Checking Type Definitions

The primary purpose of the compiler is to typecheck the schemata that users
define via the _Frontend_. The schemata terms are ADT declarations and their
types are kinds.

Currently the schema language _Compiler_ supports:

 1. type terms of kind `Type` (such as `Int` or `Bool`),

 2. and type function terms of kind `Type → Type` (such as `Maybe` or `Either`).

There are future plans to expand this to Higher Kinded Types (such as `MaybeT`,
`StateT` etc.) - subject to research into _Codegen_ of such types in the target
languages. The schema language and the _Compiler_ do support recursive
types.

Schemata terms must be monomorphically kinded, with polymorphic kinds defaulting
to monomorphic ones. For example `Phantom a = Phantom` would resolve to the
monomorphic kind `Type → Type` rather than the polymorphic kind `∀a. a → Type`.

## Checking Type Cardinality

In addition to typechecking, the compiler could perform a special check for
recursive types, namely: a check to see if a recursive type is inhabited. The
purpose of this check is to ensure that any schema which passes validation is
(in principle) a schema for which type definitions and typeclass "instances"
(which may be simple functions in languages without typeclass support) can be
generated. As an example, the compiler should be able to reject types such as
`data F a = F (F a)`, which is uninhabited. This is an additional feature that
we're currently reviewing.

## Normalising Type Definitions

Finally, the compiler should be able to _normalise_ expressions. For example, it
may be possible to define a data type in the schema language in a form similar
to: `data G a = G ((Either) ((Maybe) a) Int)`, where the bracketing indicates
the order of application within the term. The example term would normalise to
`data G a = G (Either (Maybe a) Int)` - resulting in a cleaner (and more
performant) code generation.

## Checking Typeclass Definitions and Instance Clauses

The _Compiler_ should, if possible, ensure that all instance declarations for
schemata are derivable using hard-coded derivation axioms.

Other schema languages support generating type definitions in many languages
from a single definition in the schema language. One key feature that sets
LambdaBuffers apart from these alternatives is support for
[_typeclasses_](https://en.wikipedia.org/wiki/Type_class), which enable the
generation of [ad-hoc polymorphic
functions](https://en.wikipedia.org/wiki/Ad_hoc_polymorphism) that operate on
types generated from LambdaBuffers schemata.

LambdaBuffers schema language doesn't allow users to specify typeclass instance
implementations themselves. Users, instead, will write _instance clauses_ as
part of the schema definition, and the LambdaBuffers code generator will derive
these declared instances when generating code.

Two important consequences of this design decision are:

1) _All instances must be derived structurally_. As an example, consider the
arbitrary product type `data P a b = P a b`. The semantics of the generated
instance (i.e. the behavior of the generated code) must be determinable from the
_structure of the type_ - that it is a product - and the instances for its
arguments `a` and `b`, and by those features alone. (Since `a` and `b` are type
variables here, writing a direct instance for any interesting class is likely
impossible, so LambdaBuffers supports constrained instances such as `instance (C
a, C b) => C (P a b)`)

2) _All instances must be uniform across supported languages_. Because the
LambdaBuffers codegen component (and _not_ the user) is responsible for
generating instances, we must ensure that the codegen component is suitably
equipped to generate instances in each language that exhibit behavior which is,
to the greatest extent possible, equivalent to the behavior of generated
instances in any other language. We _must_ have an extensive test quite to
verify uniform behavior of generated instances.

In languages with a typeclass system (Haskell, PureScript) or equivalent (Rust's
Traits), we will utilize the existing system and _should_ (to the extent that
doing so is feasible) utilize existing typeclasses and instances from commonly
used or standard libraries. In languages lacking a type system that is
sufficiently rich to express typeclass relations, we will generate instances
using idiomatic language features. (The details will depend on the particular
language.)

## Unsolved Problems

- [ ] How do we represent recursive types in our lambda calculus AST?

- [ ] How would cardinality checking be integrated within our current checking
      strategy?
